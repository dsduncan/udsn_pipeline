{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup\n",
    "Set up imports and read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\clone\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\clone\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\clone\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\clone\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Libraries\n",
    "from collections import namedtuple\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ingestd from database\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "engine = create_engine('sqlite:///data/DisasterResponse.db')\n",
    "qry = \"SELECT * FROM scored_messages ORDER BY message\"\n",
    "df = pd.read_sql(qry, engine)\n",
    "print(\"Data ingestd from database\")\n",
    "engine.dispose()\n",
    "\n",
    "X = df.iloc[:, :3]\n",
    "y = df.iloc[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer to use in pipeline\n",
    "def tokenize(text):\n",
    "    \"\"\"Turn string into lemmatized tokens\"\"\"\n",
    "   \n",
    "    # Basic cleaning\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9]\", \" \", text)\n",
    "    \n",
    "    # Get word tokens and remove stopwords\n",
    "    swrds = nltk.corpus.stopwords.words('english')\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [tk.strip() for tk in tokens if tk not in swrds]\n",
    "    \n",
    "    # Lemmatize thoroughly\n",
    "    lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "    lem_tok = []\n",
    "    for tok in tokens:\n",
    "        tok = lem.lemmatize(tok)\n",
    "        tok = lem.lemmatize(tok, pos='v')\n",
    "        tok = lem.lemmatize(tok, pos='a')\n",
    "        lem_tok.append(tok)\n",
    "\n",
    "    return lem_tok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, this ends up not being needed\n",
    "class ColSelect(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Transformer for splitting data by type\"\"\"\n",
    "    def __init__(self, cols, vect=False):\n",
    "        print(cols)\n",
    "        self._cols = cols\n",
    "        self._vect = vect\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # NOTE: This may not be stable, but works here\n",
    "        if self._vect:\n",
    "            return X[self._cols[0]]\n",
    "        else:\n",
    "            return X[self._cols] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_gscv():\n",
    "    \"\"\"Generate a GridSearchCV object for a text classification pipeline\"\"\"\n",
    "    \n",
    "    msgs = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer())\n",
    "    ])\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('feats', ColumnTransformer([\n",
    "            ('msgs', msgs, 'message'),\n",
    "            ('ohe', OneHotEncoder(), ['genre', 'translated'])\n",
    "        ], remainder='drop')),\n",
    "        ('clss', MultiOutputClassifier(\n",
    "            RandomForestClassifier()))\n",
    "    ])\n",
    "    \n",
    "    parameters = {\n",
    "        'clss__estimator__min_samples_leaf': range(1,2), #range(1,4),\n",
    "        'clss__estimator__min_samples_split': range(2,3), #range(2,5),\n",
    "        'clss__estimator__n_estimators': [10], #[10, 25, 50, 100, 120],\n",
    "        'feats__msgs__tfidf__smooth_idf': [False], #[False, True],\n",
    "        'feats__msgs__vect__ngram_range': [(1,1)], #[(1,1), (1,2)],        \n",
    "    }\n",
    "    \n",
    "    gscv = GridSearchCV(pipeline, parameters, cv=5)\n",
    "    \n",
    "    return gscv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('feats',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('msgs',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('vect',\n",
       "                                                                                          CountVectorizer(analyzer='word',\n",
       "                                                                                                          binary=False,\n",
       "                                                                                                          decode_error='strict',\n",
       "                                                                                                          dtype=<class 'numpy.int64'>,\n",
       "                                                                                                          encoding...\n",
       "                                                              n_jobs=None))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'clss__estimator__min_samples_leaf': range(1, 2),\n",
       "                         'clss__estimator__min_samples_split': range(2, 3),\n",
       "                         'clss__estimator__n_estimators': [10],\n",
       "                         'feats__msgs__tfidf__smooth_idf': [False],\n",
       "                         'feats__msgs__vect__ngram_range': [(1, 1)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2290)\n",
    "model = text_gscv()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clone\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scor_lst = []\n",
    "for col in range(y_test.shape[1]):\n",
    "    rpt = classification_report(\n",
    "        y_test.iloc[:, col], y_pred[:, col], output_dict=True)\n",
    "    scor_lst.append([\n",
    "        y_test.columns[col],\n",
    "        rpt['accuracy'], \n",
    "        rpt['macro avg']['precision'],\n",
    "        rpt['macro avg']['recall'],\n",
    "        rpt['macro avg']['f1-score']\n",
    "    ])\n",
    "\n",
    "scor_df = pd.DataFrame(scor_lst, columns=['class','accuracy', 'precision', 'recall','f1-score'])\n",
    "scor_df.sort_values('f1-score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.963484</td>\n",
       "      <td>0.933575</td>\n",
       "      <td>0.846010</td>\n",
       "      <td>0.883603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>weather_related</td>\n",
       "      <td>0.860199</td>\n",
       "      <td>0.845413</td>\n",
       "      <td>0.790049</td>\n",
       "      <td>0.810972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>request</td>\n",
       "      <td>0.893659</td>\n",
       "      <td>0.849010</td>\n",
       "      <td>0.735279</td>\n",
       "      <td>0.774578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>food</td>\n",
       "      <td>0.924064</td>\n",
       "      <td>0.876825</td>\n",
       "      <td>0.698730</td>\n",
       "      <td>0.752342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>storm</td>\n",
       "      <td>0.933995</td>\n",
       "      <td>0.865800</td>\n",
       "      <td>0.690741</td>\n",
       "      <td>0.744383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>aid_related</td>\n",
       "      <td>0.755080</td>\n",
       "      <td>0.753242</td>\n",
       "      <td>0.733490</td>\n",
       "      <td>0.738501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>floods</td>\n",
       "      <td>0.943774</td>\n",
       "      <td>0.912952</td>\n",
       "      <td>0.662490</td>\n",
       "      <td>0.724519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>shelter</td>\n",
       "      <td>0.933843</td>\n",
       "      <td>0.859636</td>\n",
       "      <td>0.658484</td>\n",
       "      <td>0.712095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>water</td>\n",
       "      <td>0.950497</td>\n",
       "      <td>0.901776</td>\n",
       "      <td>0.649739</td>\n",
       "      <td>0.710594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0.854240</td>\n",
       "      <td>0.788482</td>\n",
       "      <td>0.665032</td>\n",
       "      <td>0.698086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>related</td>\n",
       "      <td>0.812223</td>\n",
       "      <td>0.665431</td>\n",
       "      <td>0.636979</td>\n",
       "      <td>0.646966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>transport</td>\n",
       "      <td>0.956455</td>\n",
       "      <td>0.824807</td>\n",
       "      <td>0.560729</td>\n",
       "      <td>0.594068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>clothing</td>\n",
       "      <td>0.986096</td>\n",
       "      <td>0.951445</td>\n",
       "      <td>0.554378</td>\n",
       "      <td>0.593839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>death</td>\n",
       "      <td>0.958442</td>\n",
       "      <td>0.916977</td>\n",
       "      <td>0.557547</td>\n",
       "      <td>0.591671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>buildings</td>\n",
       "      <td>0.953094</td>\n",
       "      <td>0.831618</td>\n",
       "      <td>0.550862</td>\n",
       "      <td>0.578594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>cold</td>\n",
       "      <td>0.981513</td>\n",
       "      <td>0.919461</td>\n",
       "      <td>0.545646</td>\n",
       "      <td>0.578085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>medical_products</td>\n",
       "      <td>0.951872</td>\n",
       "      <td>0.865306</td>\n",
       "      <td>0.541147</td>\n",
       "      <td>0.563089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>military</td>\n",
       "      <td>0.966845</td>\n",
       "      <td>0.823972</td>\n",
       "      <td>0.536978</td>\n",
       "      <td>0.559278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>medical_help</td>\n",
       "      <td>0.919328</td>\n",
       "      <td>0.770647</td>\n",
       "      <td>0.533912</td>\n",
       "      <td>0.543209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>electricity</td>\n",
       "      <td>0.981054</td>\n",
       "      <td>0.919165</td>\n",
       "      <td>0.523178</td>\n",
       "      <td>0.539331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>money</td>\n",
       "      <td>0.978610</td>\n",
       "      <td>0.864445</td>\n",
       "      <td>0.520677</td>\n",
       "      <td>0.534063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>0.973262</td>\n",
       "      <td>0.861768</td>\n",
       "      <td>0.516603</td>\n",
       "      <td>0.525304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>missing_people</td>\n",
       "      <td>0.988388</td>\n",
       "      <td>0.744269</td>\n",
       "      <td>0.506502</td>\n",
       "      <td>0.509900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>refugees</td>\n",
       "      <td>0.966998</td>\n",
       "      <td>0.650747</td>\n",
       "      <td>0.508802</td>\n",
       "      <td>0.509463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>other_aid</td>\n",
       "      <td>0.873186</td>\n",
       "      <td>0.692022</td>\n",
       "      <td>0.520141</td>\n",
       "      <td>0.508885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>offer</td>\n",
       "      <td>0.995264</td>\n",
       "      <td>0.497632</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>shops</td>\n",
       "      <td>0.994805</td>\n",
       "      <td>0.497403</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>tools</td>\n",
       "      <td>0.993736</td>\n",
       "      <td>0.496868</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>hospitals</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.495798</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.497890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>aid_centers</td>\n",
       "      <td>0.990222</td>\n",
       "      <td>0.495111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.497543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>fire</td>\n",
       "      <td>0.988846</td>\n",
       "      <td>0.494423</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.497196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>other_weather</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.606840</td>\n",
       "      <td>0.504826</td>\n",
       "      <td>0.496931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>infrastructure_related</td>\n",
       "      <td>0.938426</td>\n",
       "      <td>0.636575</td>\n",
       "      <td>0.505468</td>\n",
       "      <td>0.496212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>security</td>\n",
       "      <td>0.983193</td>\n",
       "      <td>0.491897</td>\n",
       "      <td>0.499689</td>\n",
       "      <td>0.495763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>other_infrastructure</td>\n",
       "      <td>0.956303</td>\n",
       "      <td>0.478297</td>\n",
       "      <td>0.499840</td>\n",
       "      <td>0.488832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     class  accuracy  precision    recall  f1-score\n",
       "31              earthquake  0.963484   0.933575  0.846010  0.883603\n",
       "27         weather_related  0.860199   0.845413  0.790049  0.810972\n",
       "1                  request  0.893659   0.849010  0.735279  0.774578\n",
       "10                    food  0.924064   0.876825  0.698730  0.752342\n",
       "29                   storm  0.933995   0.865800  0.690741  0.744383\n",
       "3              aid_related  0.755080   0.753242  0.733490  0.738501\n",
       "28                  floods  0.943774   0.912952  0.662490  0.724519\n",
       "11                 shelter  0.933843   0.859636  0.658484  0.712095\n",
       "9                    water  0.950497   0.901776  0.649739  0.710594\n",
       "34           direct_report  0.854240   0.788482  0.665032  0.698086\n",
       "0                  related  0.812223   0.665431  0.636979  0.646966\n",
       "19               transport  0.956455   0.824807  0.560729  0.594068\n",
       "12                clothing  0.986096   0.951445  0.554378  0.593839\n",
       "16                   death  0.958442   0.916977  0.557547  0.591671\n",
       "20               buildings  0.953094   0.831618  0.550862  0.578594\n",
       "32                    cold  0.981513   0.919461  0.545646  0.578085\n",
       "5         medical_products  0.951872   0.865306  0.541147  0.563089\n",
       "8                 military  0.966845   0.823972  0.536978  0.559278\n",
       "4             medical_help  0.919328   0.770647  0.533912  0.543209\n",
       "21             electricity  0.981054   0.919165  0.523178  0.539331\n",
       "13                   money  0.978610   0.864445  0.520677  0.534063\n",
       "6        search_and_rescue  0.973262   0.861768  0.516603  0.525304\n",
       "14          missing_people  0.988388   0.744269  0.506502  0.509900\n",
       "15                refugees  0.966998   0.650747  0.508802  0.509463\n",
       "17               other_aid  0.873186   0.692022  0.520141  0.508885\n",
       "2                    offer  0.995264   0.497632  0.500000  0.498813\n",
       "24                   shops  0.994805   0.497403  0.500000  0.498698\n",
       "22                   tools  0.993736   0.496868  0.500000  0.498429\n",
       "23               hospitals  0.991597   0.495798  0.500000  0.497890\n",
       "25             aid_centers  0.990222   0.495111  0.500000  0.497543\n",
       "30                    fire  0.988846   0.494423  0.500000  0.497196\n",
       "33           other_weather  0.945455   0.606840  0.504826  0.496931\n",
       "18  infrastructure_related  0.938426   0.636575  0.505468  0.496212\n",
       "7                 security  0.983193   0.491897  0.499689  0.495763\n",
       "26    other_infrastructure  0.956303   0.478297  0.499840  0.488832"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package model with evaluation and output to pickle\n",
    "ModelOutput = namedtuple('ModelOutput', 'class_rept mod_obj')\n",
    "mod_out = ModelOutput(scor_df, model)\n",
    "\n",
    "with open('text_scorer.pkl', 'wb') as f:\n",
    "    pickle.dump(mod_out, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
